{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\helde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing all the relevant packages.\n",
    "\n",
    "import spacy #This statement should work if you have spaCy installed \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "!python -m textblob.download_corpora\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the amazon reviews\n",
    "data = pd.read_csv(\"amazon_product_reviews.csv\", index_col=0)\n",
    "\n",
    "reviews_data=data[['reviews.text']]\n",
    "\n",
    "# cleaning the data:\n",
    "clean_data=reviews_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought it would be as big as small paper bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This kindle is light and easy to use especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Didnt know how much i'd use a kindle so went f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am 100 happy with my purchase. I caught it o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Solid entry level Kindle. Great for kids. Gift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>This is a great tablet for the price. Amazon i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>This tablet is the perfect size and so easy to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Purchased this for my son. Has room to upgrade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>I had some thoughts about getting this for a 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>this is a steal, have 8 gb model as well.This ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviews.text\n",
       "0     I thought it would be as big as small paper bu...\n",
       "1     This kindle is light and easy to use especiall...\n",
       "2     Didnt know how much i'd use a kindle so went f...\n",
       "3     I am 100 happy with my purchase. I caught it o...\n",
       "4     Solid entry level Kindle. Great for kids. Gift...\n",
       "...                                                 ...\n",
       "4995  This is a great tablet for the price. Amazon i...\n",
       "4996  This tablet is the perfect size and so easy to...\n",
       "4997  Purchased this for my son. Has room to upgrade...\n",
       "4998  I had some thoughts about getting this for a 5...\n",
       "4999  this is a steal, have 8 gb model as well.This ...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data=reviews_data.dropna(subset=['reviews.text'])\n",
    "\n",
    "#Dropping the index column with the id. We will now only have 5000 numerical rows.\n",
    "clean_data.reset_index(drop=True, inplace=True)\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I thought it would be as big as small paper but turn out to be just like my palm. I think it is too small to read on it... not very comfortable as regular Kindle. Would definitely recommend a paperwhite instead.\n",
      "-0.10897435897435898\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "# Attempting to extract a review as a text from the clean_data frame\n",
    "first_review=clean_data['reviews.text'][0]\n",
    "print(first_review)\n",
    "\n",
    "doc = nlp(first_review)\n",
    "\n",
    "print(doc._.blob.polarity )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text using spaCy\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "\n",
    "# Creating 3 empty lists to store the sentiment and reviews.\n",
    "sent_score_list=[]      #Sentiment Score list, float\n",
    "sent_type=[]            #Sentiment type, string -> Positive, Neutral , Negative\n",
    "rev_list=[]             #Reviews list, string\n",
    "\n",
    "# Looping through the reviews and placing them into a list.\n",
    "for i in range(0,len(clean_data)):\n",
    "    \n",
    "    clean_data['reviews.text'][i]\n",
    "\n",
    "    # Extracting the reviews and appending them to rev_list\n",
    "    reviews=preprocess(clean_data['reviews.text'][i])\n",
    "    rev_list.append(reviews)\n",
    "\n",
    "    # Extracting the reviews and working out its polarity and appending it to the sent_score_list\n",
    "    sentiment=nlp(preprocess(clean_data['reviews.text'][i]))\n",
    "    sent_score_list.append(sentiment._.blob.polarity)\n",
    "\n",
    "    # Adding the classification of the sentiment: positive, neutral and negative depending on the polarity score\n",
    "    if sentiment._.blob.polarity==0:\n",
    "        sent_type.append(\"Neutral\")\n",
    "    elif sentiment._.blob.polarity<0:\n",
    "        sent_type.append(\"Negative\")\n",
    "    else:\n",
    "        sent_type.append(\"Positive\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Sentiment_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>think big small paper turn like palm think sma...</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kindle light easy use especially beach</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not know use kindle go low end m happy little ...</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy purchase catch sale good price normally ...</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solid entry level kindle great kid gifted kid ...</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>great tablet price amazon good job</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>tablet perfect size easy use read play game pu...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>purchase son room upgrade memory allow book ga...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>thought get year old screen protector case fee...</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>steal gb model punch</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  Sentiment_Score  \\\n",
       "0     think big small paper turn like palm think sma...        -0.016667   \n",
       "1                kindle light easy use especially beach         0.277778   \n",
       "2     not know use kindle go low end m happy little ...         0.115625   \n",
       "3     happy purchase catch sale good price normally ...         0.276786   \n",
       "4     solid entry level kindle great kid gifted kid ...         0.443333   \n",
       "...                                                 ...              ...   \n",
       "4995                 great tablet price amazon good job         0.750000   \n",
       "4996  tablet perfect size easy use read play game pu...         0.458333   \n",
       "4997  purchase son room upgrade memory allow book ga...        -0.400000   \n",
       "4998  thought get year old screen protector case fee...         0.025000   \n",
       "4999                               steal gb model punch         0.000000   \n",
       "\n",
       "     Sentiment_Type  \n",
       "0          Negative  \n",
       "1          Positive  \n",
       "2          Positive  \n",
       "3          Positive  \n",
       "4          Positive  \n",
       "...             ...  \n",
       "4995       Positive  \n",
       "4996       Positive  \n",
       "4997       Negative  \n",
       "4998       Positive  \n",
       "4999        Neutral  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the lists into numpy arrays\n",
    "sent_score_arr = np.array(sent_score_list)\n",
    "sent_type_arr = np.array(sent_type)\n",
    "rev_arr = np.array(rev_list)\n",
    "\n",
    "#creating 3 dataframes: Reviews , Sentiment_Score and Sentiment_Type\n",
    "rev_df=pd.DataFrame(rev_arr)\n",
    "sent_score_df=pd.DataFrame(sent_score_arr)\n",
    "sent_type_df=pd.DataFrame(sent_type_arr)\n",
    "\n",
    "# Concatenating the separate data frames into a single data frame\n",
    "sent_analysis_df=pd.concat([rev_df,sent_score_df,sent_type_df],axis=1)\n",
    "sent_analysis_df.columns=['Reviews','Sentiment_Score','Sentiment_Type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to preprocess text using spaCy\n",
    "# def preprocess(text):\n",
    "#     doc = nlp(text)\n",
    "#     cleaned_tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "#     return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_text=\"I thought it would be as big as small paper but turn out to be just like my palm. I think it is too small to read on it... not very comfortable as regular Kindle. Would definitely recommend a paperwhite instead.\"\n",
    "\n",
    "# preprocess(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(0,len(clean_data)):\n",
    "    \n",
    "#     preprocessed_sent=preprocess(clean_data['reviews.text'][i])\n",
    "#     print(preprocessed_sent)\n",
    "\n",
    "# preprocessed_sent=preprocess(clean_data['reviews.text'][0])\n",
    "# type(preprocessed_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sent_analysis_df['Reviews'], sent_analysis_df['Sentiment_Type'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer with and without preprocessing\n",
    "vectorizer_unprocessed = CountVectorizer()\n",
    "X_train_unprocessed = vectorizer_unprocessed.fit_transform(X_train)\n",
    "X_test_unprocessed = vectorizer_unprocessed.transform(X_test)\n",
    "\n",
    "# vectorizer_processed = CountVectorizer(preprocessor=preprocess)\n",
    "# X_train_processed = vectorizer_processed.fit_transform(X_train)\n",
    "# X_test_processed = vectorizer_processed.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without preprocessing:\n",
      "Accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.19      0.31        53\n",
      "     Neutral       1.00      0.06      0.11        69\n",
      "    Positive       0.89      1.00      0.94       878\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.91      0.41      0.45      1000\n",
      "weighted avg       0.89      0.89      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier on the unprocessed data\n",
    "clf_unprocessed = MultinomialNB()\n",
    "clf_unprocessed.fit(X_train_unprocessed, y_train)\n",
    "y_pred_unprocessed = clf_unprocessed.predict(X_test_unprocessed)\n",
    "\n",
    "print(\"Results without preprocessing:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_unprocessed)}\")\n",
    "print(classification_report(y_test, y_pred_unprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with preprocessing:\n",
      "Accuracy: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.17      0.28        53\n",
      "     Neutral       1.00      0.06      0.11        69\n",
      "    Positive       0.89      1.00      0.94       878\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.90      0.41      0.44      1000\n",
      "weighted avg       0.89      0.89      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Train a Naive Bayes classifier on the preprocessed data\n",
    "# clf_processed = MultinomialNB()\n",
    "# clf_processed.fit(X_train_processed, y_train)\n",
    "# y_pred_processed = clf_processed.predict(X_test_processed)\n",
    "\n",
    "# print(\"\\nResults with preprocessing:\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred_processed)}\")\n",
    "# print(classification_report(y_test, y_pred_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_analysis_df[\"Sentiment_Type\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3360 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
